
# input masks are generated by deforming the binary segmentation mask: 
#		(two masks generated for each ground truth in the training set)

# i) affine transformation: random scaling +/- 5% of object size and translation +/- 10% shift

# ii) non-rigid deformation: thin-plate splines using 5 control points and randomly shifting the points in x and y directions 
#		within +/- 10% margin of the original mask width and height

# iii) coarsening: dilation operation with 5 pixel radius 

import tensorflow as tf

import os
import pandas as pd
import numpy as np
import collections
import cv2
import skimage.draw
import matplotlib.pyplot as plt
from skimage.transform import warp, AffineTransform
from skimage.morphology import dilation
import tensorflow_addons as tfa


def affine_transform(mask):
	width, height, ch  = np.shape(mask)
	# random scaling between -0.1 and 0.1
	scale_val = 0.2 * np.random.random_sample() - 0.1
	# translation between -0.1 and 0.1
	translation_val = 0.2 * np.random.random_sample() - 0.1
	tform = AffineTransform(scale=(1.0 + scale_val, 1.0 + scale_val), translation = (width * translation_val, height * translation_val))

	affine = warp(mask, tform.inverse)
	affine = np.where(affine < 0.5, 0.0, 1.0)

	footprint = np.array([[0,0,1,0,0],[0,1,1,1,0], [1,1,1,1,1], [0,1,1,1,0], [0,0,1,0,0]])
	# coarsen the mask
	affine = dilation(affine[:,:,0], footprint)

	return affine

def non_rigid_def(mask):
	width, height, ch  = np.shape(mask)
	# Non-rigid deformation
	footprint = np.array([[0,1,0], [1,1,1], [0,1,0]])
	# find points on the boundary of the mask
	bound = dilation(mask[:,:,0], footprint) - mask[:,:,0]
	pts = np.argwhere(bound)

	#Find the max width and height of the mask 
	y_max = np.max(pts[:, 0]); y_min = np.min(pts[:, 0])
	x_max = np.max(pts[:, 1]); x_min = np.min(pts[:, 1])
	h = y_max - y_min
	w = x_max - x_min

	mask = np.expand_dims(mask, axis=0)

	done = False

	#Ensure that there are more than 4 boundary points 
	while not done:
		if np.shape(pts)[0] > 4:
			# choose 5 control points 
			num_control = 5
			control = np.random.choice(range(0, np.shape(pts)[0]),num_control, replace=False)
			new_pts = pts[control]
			original_pts = pts[control]

			for point in new_pts:
				# Shift each point in the x and y directions within +/- 10% margin of the original width and height
				point[1] = point[1] + w * (0.2 * np.random.random_sample() - 0.1)
				point[0] = point[0] + h * (0.2 * np.random.random_sample() - 0.1)

			# Create surface that is tpaps of the new_pts and original_pts
			q_x = new_pts[:, 1]; q_y = new_pts[:, 0] # shape = (N, )
			p_x = original_pts[:,1]; p_y = original_pts[:,0] 

			# Create the L-inverse matrix to solve the tps equation
			q_x = np.expand_dims(q_x, axis=1); q_y = np.expand_dims(q_y, axis=1) # shape = (N, 1)
			x_mat = np.repeat(q_x, num_control, axis=1) # shape = (N, N)
			y_mat = np.repeat(q_y, num_control, axis=1) # shape = (N, N)

			p_dist_squared = np.square(x_mat - np.transpose(x_mat)) + np.square(y_mat - np.transpose(y_mat)) # shape = (N,N)
			# to take log of p_dist_squared, remove all the zeros 
			p_dist_squared = np.where(p_dist_squared == 0, 1.0, p_dist_squared)
			
			K = p_dist_squared * np.log(p_dist_squared) # shape = (N,N)
			O = np.ones((num_control, 1))
			Z = np.zeros((3,3))
			P = np.concatenate((O, q_x, q_y), axis=1) # shape = (N, 3)

			# L = | K   | P |  shape = (N+3, N+3)
			#     | P^T | O |
			L = np.concatenate((np.concatenate((K, P), axis=1), np.concatenate((np.transpose(P), Z), axis=1)), axis=0)
			# Check to see if matrix is invertable, if not redo
			if(np.linalg.matrix_rank(L) == L.shape[0] and L.shape[0] == L.shape[1]):
				Li = np.linalg.inv(L)

				# Define the vector w
				w_x = np.matmul(Li[:num_control,:num_control], p_x) # shape = (N, )
				w_y = np.matmul(Li[:num_control,:num_control], p_y) # shape = (N, )

				# Define the vector a 
				a_x = np.matmul(Li[num_control:,:num_control], p_x) # shape = (3, )
				a_y = np.matmul(Li[num_control:,:num_control], p_y) # shape = (3, )

				grid_Y, grid_X = np.meshgrid(np.linspace(0, width * 2, width), np.linspace(0, height * 2, height)) #shape = (width, height)

				grid_Y = np.expand_dims(grid_Y, axis=2)
				grid_X = np.expand_dims(grid_X, axis=2)
				points = np.concatenate((grid_X, grid_Y), axis=2) # shape = (width, height, 2)

				points_x = points[:,:,0] # shape = (width, height)
				points_y = points[:,:,1] # shape = (width, height)

				q_x = np.expand_dims(q_x, axis=(0, 1, 2))
				q_x = np.squeeze(q_x, axis= -1)  # shape = (1,1,1,N)

				q_y = np.expand_dims(q_y, axis=(0, 1, 2))
				q_y= np.squeeze(q_y, axis= -1) # shape = (1,1,1,N)
				
				delta_x = q_x - np.expand_dims(points_x, axis=-1) # shape = (1, width, height, N)
				delta_y = q_y - np.expand_dims(points_y, axis=-1) # shape = (1, width, height, N)
			
				dist_squared = np.square(delta_x) + np.square(delta_y)
				# Remove zero values 
				dist_squared = np.where(dist_squared == 0, 1.0, dist_squared)

				U = dist_squared * np.log(dist_squared) # shape = (1, width, height, N)
				
				points_x_prime = a_x[0] + (a_x[1] * points_x) + (a_x[2] * points_y)  + np.sum((w_x*U)) # shape = (width, height)
				points_y_prime = a_y[0] + (a_y[1] * points_x) + (a_y[2] * points_y)  + np.sum((w_y*U)) # shape = (width, height)
				
				points_x_prime = np.expand_dims(points_x_prime, axis=-1)
				points_y_prime = np.expand_dims(points_y_prime, axis=-1)
				tps = np.concatenate((points_x_prime, points_y_prime), axis=-1) # shape = (width, height, 2)

				# Attempt to interpolate 
				new_max = width
				new_min = 0
				grid_x = (new_max - new_min) / (np.ndarray.max(tps[:, :, 1]) - np.ndarray.min(tps[ :, :, 1])) * (tps[:, :, 1] - np.ndarray.max(tps[:, :, 1])) + new_max

				new_max = height
				new_min = 0
				grid_y = (new_max - new_min) / (np.ndarray.max(tps[ :, :, 0]) - np.ndarray.min(tps[:, :, 0])) * (tps[:, :, 0] - np.ndarray.max(tps[:, :, 0])) + new_max

				grid = np.stack([grid_x, grid_y], axis=-1) #shape = (width, height 2)
				grid = np.expand_dims(grid, axis=0)
			
				final_image = tfa.image.resampler(tf.convert_to_tensor(mask), tf.convert_to_tensor(grid))
				footprint = np.array([[0,0,1,0,0], [0,1,1,1,0], [1,1,1,1,1], [0,1,1,1,0], [0, 0,1,0, 0]])
				# find points on the boundary of the mask
				final_image = dilation(final_image[0,:,:,0], footprint)
				final_image = np.where(final_image >= 0.5, 1, 0)

				# Ensure that the new points are bounded, if they are not redo
				footprint = np.array([[0,1,0], [1,1,1], [0,1,0]])
				new_bound = dilation(final_image, footprint) - final_image
				pts_nr = np.argwhere(new_bound)

				# Ensure that the the points arrays exist
				if pts_nr[:,0].size != 0 and pts_nr[:,1].size != 0:
					#Find the max width and height of the mask 
					y_max_nr = np.max(pts_nr[:, 0]); y_min_nr = np.min(pts_nr[:, 0])
					x_max_nr = np.max(pts_nr[:, 1]); x_min_nr = np.min(pts_nr[:, 1])
					h_nr = y_max_nr - y_min_nr
					w_nr = x_max_nr - x_min_nr

					if( h_nr <= h * 1.5) and (w_nr <= w*1.5):
						done = True
	footprint = np.array([[0,0,1,0,0],[0,1,1,1,0], [1,1,1,1,1], [0,1,1,1,0], [0,0,1,0,0]])
	# coarsen the mask
	final_image = dilation(final_image, footprint)

	return final_image

def augment_masks(original_masks):
	# This function is based on the mask augmentation Matlab script from:
	#  http://www.mpi-inf.mpg.de/masktrack
	
	# input shape: (2, w, h, 1)
	# output shape: (4, w, h,1)
	im,width,height,ch = np.shape(original_masks)

	ED = original_masks[0]
	ES = original_masks[1]

	# fig, axs = plt.subplots(1, 3, sharey=True, tight_layout=True)
	# axs[0].imshow(ES)
	# axs[1].imshow(ES_aff)
	# axs[2].imshow(ES_nr)
	# plt.show()

	zeros = np.zeros((1, width,height))

	# print(np.shape(ED_aff))
	# print(np.shape(ED_nr))
	output = []

	for i in range(0, 3):
		ED_aff = affine_transform(ED)
		ED_nr= non_rigid_def(ED)
		output=np.append(output, ED_aff)
		output= np.append(output, ED_nr)

		output = np.reshape(output, (-1,width,height))

	output = np.append(output, zeros, axis=0)
	for i in range(0, 3):
		ES_aff = affine_transform(ES)
		ES_nr = non_rigid_def(ES)
		output=np.append(output, ES_aff)
		output= np.append(output, ES_nr)

		output = np.reshape(output, (-1,width,height))

	output = np.append(output, zeros, axis=0)

	output = np.expand_dims(output, axis = -1)
	
	return output

class EchoMasks(tf.keras.utils.Sequence):
	def __init__(self, root = "EchoNet-Dynamic/",split='train', batch_size = 1, padding = None, noise =None):
		self.folder = root
		self.split = split
		self.batch_size = batch_size
		self.pad = padding
		self.noise = noise


		self.fnames =[]
		self.outcomes =[]
		self.ejection=[]
		self.fps = []

		with open(self.folder + "FileList.csv") as f:
			header   = f.readline().strip().split(",")
			filenameIndex = header.index("FileName")
			splitIndex = header.index("Split")
			efIndex = header.index("EF")
			fpsIndex = header.index("FPS")
			for line in f:
				lineSplit = line.strip().split(',')
				# Get name of the video file
				fileName = os.path.splitext(lineSplit[filenameIndex])[0]+".avi"
				
				#Get the subset that the video belongs to 
				fileSet = lineSplit[splitIndex].lower()
				
				#Get ef for the video
				fileEf = lineSplit[efIndex]

				#Get fps for the video
				fileFps = lineSplit[fpsIndex]

				#Ensure that the video exists 
				if os.path.exists(self.folder + "/Videos/" + fileName):
					if fileSet == split:
						self.fnames.append(fileName)
						self.outcomes.append(lineSplit)
						self.ejection.append(fileEf)
						self.fps.append(fileFps)

		self.frames = collections.defaultdict(list)
		_defaultdict_of_lists_ = collections.defaultdict(list)
		self.trace = collections.defaultdict(lambda: collections.defaultdict(list))

		#Read the voilume tracings CSV file to find videos with ED/ES frames 
		with open(self.folder + "VolumeTracings.csv") as f:
			header = f.readline().strip().split(",")
			assert header == ["FileName", "X1", "Y1", "X2", "Y2", "Frame"]

			for line in f:
				filename, x1, y1, x2, y2, frame = line.strip().split(",")
				x1 = float(x1)
				x2 = float(x2)
				y1 = float(y1)
				y2 = float(y2)
				frame = int(frame)

				# New frame index for the given filename
				if frame not in self.trace[filename]:
					self.frames[filename].append(frame)
				self.trace[filename][frame].append((x1,y1,x2,y2))

		#Transform into numpy array 
		for filename in self.frames:
			for frame in self.frames[filename]:
				self.trace[filename][frame] = np.array(self.trace[filename][frame])

		# Reject files without tracings 
		keep = [len(self.frames[f]) >= 2 for f in self.fnames]
		self.fnames = [f for (f, k) in zip(self.fnames, keep) if k]
		self.outcomes = [f for (f, k) in zip(self.outcomes, keep) if k]

		self.indexes = np.arange(np.shape(self.fnames)[0])

	def __len__(self):
		# Denotes the number of batches per epoch
		return(int (np.floor(np.shape(self.fnames)[0])/self.batch_size))

	def __getitem__(self, idx):
		# Generate one batch of datas
		# Generate indexes of the batch

		indexes = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]
		X, y = self.__data_generation(indexes) #X = [6,128,128,4]

		#Do some augmentations
		ed = X[0, :, :, 0:3]
		es = X[7, :, :, 0:3]

		ed_maskchannels = np.expand_dims(X[0:7, :, :,3], axis=-1)
		es_maskchannels = np.expand_dims(X[7:14, :, :,3], axis=-1)

		ed_y= y[0:7]
		es_y = y[7:14]

		ed_brightness = tf.image.random_brightness(ed, 0.3)
		ed_brightness = np.repeat(np.expand_dims(ed_brightness, axis=0), 7, axis=0)
		ed_brightness = np.append(ed_brightness,ed_maskchannels,axis=-1)
		X = np.append(X, ed_brightness, axis=0)
		y = np.append(y, ed_y, axis=0)

		es_brightness = tf.image.random_brightness(es, 0.3)
		es_brightness = np.repeat(np.expand_dims(es_brightness, axis=0), 7, axis=0)
		es_brightness = np.append(es_brightness,es_maskchannels,axis=-1)
		X = np.append(X, es_brightness, axis=0)
		y = np.append(y, es_y,  axis=0)

		ed_contrast = tf.image.random_contrast(ed, 0.2, 0.5)
		ed_contrast = np.repeat(np.expand_dims(ed_contrast, axis=0), 7, axis=0)
		ed_contrast = np.append(ed_contrast,ed_maskchannels,axis=-1)
		X = np.append(X, ed_contrast, axis=0)
		y = np.append(y, ed_y,  axis=0)

		es_contrast = tf.image.random_contrast(es, 0.2, 0.5)
		es_contrast = np.repeat(np.expand_dims(es_contrast, axis=0), 7, axis=0)
		es_contrast = np.append(es_contrast, es_maskchannels,axis=-1)
		X = np.append(X, es_contrast, axis=0)
		y = np.append(y, es_y,  axis=0)

		#Rotate some:

		rot_factor = tf.cast(tf.random.uniform(shape=[], maxval=12, dtype=tf.int32), tf.float32)
		angle = np.pi/12*rot_factor
		ed_rot = tfa.image.rotate(X[0:7], angle)
		ed_y_rot = tfa.image.rotate(ed_y, angle)

		X = np.append(X, ed_rot, axis=0)
		y = np.append(y, ed_y_rot,  axis=0)



		rot_factor = tf.cast(tf.random.uniform(shape=[], maxval=12, dtype=tf.int32), tf.float32)
		angle = np.pi/12*rot_factor

		es_rot = tfa.image.rotate(X[7:14], angle)
		es_y_rot = tfa.image.rotate(es_y, angle)

		X = np.append(X, es_rot, axis=0)
		y = np.append(y, es_y_rot,  axis=0)

		return X, y


	def __data_generation(self, list_IDs_temp):

		X = []
		y = []

		index = 0
		for i in list_IDs_temp:
			path = os.path.join(self.folder, "Videos", self.fnames[i])
			# Load video into np.array
			if not os.path.exists(path):
				print("File does not exist")

			frames = self.frames[self.fnames[i]]
			frames.sort() #  Ensure that the frames are in ascending order
			traces = self.trace[self.fnames[i]]

			vid_cap = cv2.VideoCapture(path)
			frame_count = int(vid_cap.get(cv2.CAP_PROP_FRAME_COUNT))
			frame_width = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))
			frame_height = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

			# Read the entire video and save the traced frames 
			inputs = np.zeros((len(frames),frame_width, frame_height, 3), np.uint8)
			targets = np.zeros((len(frames),frame_width, frame_height), np.uint8)
			index = 0
			
			# Load the frames  
			for count in range(frame_count): 
				success, frame = vid_cap.read()
				if not success:
					print("Failed to load frame #", count, ' of ', filename)
				
				if (count) in frames: #Assume that frame number is 1 indexed
					frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
					inputs[index] = frame
					index = index + 1
			
			if self.noise:
				num_pepper = np.ceil(self.noise * 2 * frame_height * frame_width)
				coords = [np.random.randint(0, i-1, int(num_pepper)) for i in inputs.shape[0:3]]
				inputs[tuple(coords)] = (0,0,0)
			
			# Scale pixels between 0 and 1
			inputs = inputs /255.0
			X = np.append(X, inputs)
			X = X.reshape((-1, 112,112,3))
	
			#Load the targets
			index = 0
			for f in frames:
				t = traces[f]
				x1, y1, x2, y2 = t[:, 0], t[:, 1], t[:, 2], t[:, 3]
				x = np.concatenate((x1[1:], np.flip(x2[1:])))
				y_ = np.concatenate((y1[1:], np.flip(y2[1:])))
				r, c = skimage.draw.polygon(np.rint(y_).astype(np.int), np.rint(x).astype(np.int), (frame_width,frame_height))
				mask = np.zeros((frame_width, frame_height), np.float32)
				mask[r, c] = 1
				targets[index] = mask
				index = index + 1	

			y = np.append(y, targets)
			y = y.reshape(-1, 112, 112)

		y = np.expand_dims(y, -1)

		# take the ED and ES masks and return the four deformed training masks (MaskTrack)
		aug_masks = augment_masks(y)

		y = np.repeat(y, 7, axis=0) # shape = (6, width, height, 1)
		X = np.repeat(X, 7, axis=0) # shape = (6, width, height, 3)


		# Add the extra mask channel
		X = np.append(X, aug_masks, axis=-1) #shape = (6, 112, 112, 4)

		if self.pad is not None:
			X = np.pad(X, ((0,0),(self.pad,self.pad),(self.pad,self.pad),(0,0)), mode='constant', constant_values=0)
			y = np.pad(y, ((0,0),(self.pad,self.pad),(self.pad,self.pad), (0,0)), mode='constant', constant_values=0)

		return X, y

	def display_example(self, idx):
		indexes = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]
		X, y = self.__data_generation(indexes)

		fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)
		axs[0].imshow(X[0])
		axs[0].set_title("First Frame")
		axs[1].imshow(y[0])
		axs[1].set_title("First Mask")
		plt.show()

		fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)
		axs[0].imshow(X[1])
		axs[0].set_title("Second Frame")
		axs[1].imshow(y[1])
		axs[1].set_title("Second Mask")
		plt.show()

# Define packed tensor so that we can have a segmentation mask ground truth and a EF ground truth
class PackedTensor(tf.experimental.BatchableExtensionType):
    __name__ = 'extension_type_colab.PackedTensor'

    ef: tf.Tensor
    video_masks: tf.Tensor
    ed_es_frames: tf.Tensor
    edv : tf.Tensor
    esv : tf.Tensor

    # shape and dtype hold no meaning in this context, so we use a dummy
    # to stop Keras from complaining

    shape = property(lambda self: self.output_0.shape)
    dtype = property(lambda self: self.output_0.dtype)

    class Spec:

        def __init__(self, shape, dtype=tf.float32):

        	self.ef = tf.TensorSpec(shape, dtype)
        	self.video_masks = tf.TensorSpec(shape, dtype)
        	self.ed_es_frames = tf.TensorSpec(shape, dtype)
        	self.edv = tf.TensorSpec(shape, dtype)
        	self.esv = tf.TensorSpec(shape, dtype)

        # shape and dtype hold no meaning in this context, so we use a dummy
        # to stop Keras from complaining
        shape: tf.TensorShape = tf.constant(1.).shape 
        dtype: tf.DType = tf.constant(1.).dtype

# these two functions have no meaning, but need dummy implementations
# to stop Keras from complaining
@tf.experimental.dispatch_for_api(tf.shape)
def packed_shape(input: PackedTensor, out_type=tf.int32, name=None):
    return tf.shape(input.col_ids)

@tf.experimental.dispatch_for_api(tf.cast)
def packed_cast(x: PackedTensor, dtype: str, name=None):
    return x

class EchoSet(tf.keras.utils.Sequence):
	def __init__(self, root = "EchoNet-Dynamic/", split='train', max_length = 32, min_spacing = 16, pad = 8, attenuation = 3, batch_size =1,  center=True):
		self.folder = root
		self.split = split
		self.max_length = max_length
		self.min_length = min_spacing
		self.pad = pad
		self.attenuation = attenuation
		self.batch_size = batch_size
		self.center = center


		self.fnames =[]
		self.outcomes =[]
		self.ejection=[]
		self.fps = []
		self.edv = []
		self.esv = []
		
		with open(self.folder + "FileList.csv") as f:
			header   = f.readline().strip().split(",")
			filenameIndex = header.index("FileName")
			splitIndex = header.index("Split")
			efIndex = header.index("EF")
			fpsIndex = header.index("FPS")

			edvIndex = header.index("EDV")	
			esvIndex = header.index("ESV")


			for line in f:
				lineSplit = line.strip().split(',')
				# Get name of the video file
				fileName = os.path.splitext(lineSplit[filenameIndex])[0]+".avi"
				
				#Get the subset that the video belongs to 
				fileSet = lineSplit[splitIndex].lower()
				
				#Get ef for the video
				fileEf = lineSplit[efIndex]

				#Get fps for the video
				fileFps = lineSplit[fpsIndex]

				# Get the EDV and ESV for the video 
				fileEDV = lineSplit[edvIndex]
				fileESV = lineSplit[esvIndex]

				#Ensure that the video exists 
				if os.path.exists(self.folder + "/Videos/" + fileName):
					if fileSet == split:
						self.fnames.append(fileName)
						self.outcomes.append(lineSplit)
						self.ejection.append(fileEf)
						self.fps.append(fileFps)
						self.edv.append(fileEDV)
						self.esv.append(fileESV)

		self.frames = collections.defaultdict(list)
		_defaultdict_of_lists_ = collections.defaultdict(list)
		self.trace = collections.defaultdict(lambda: collections.defaultdict(list))

		#Read the voilume tracings CSV file to find videos with ED/ES frames 
		with open(self.folder + "VolumeTracings.csv") as f:
			header = f.readline().strip().split(",")
			assert header == ["FileName", "X1", "Y1", "X2", "Y2", "Frame"]

			for line in f:
				filename, x1, y1, x2, y2, frame = line.strip().split(",")
				x1 = float(x1)
				x2 = float(x2)
				y1 = float(y1)
				y2 = float(y2)
				frame = int(frame)

				# New frame index for the given filename
				if frame not in self.trace[filename]:
					self.frames[filename].append(frame)
				self.trace[filename][frame].append((x1,y1,x2,y2))

		#Transform into numpy array 
		for filename in self.frames:
			for frame in self.frames[filename]:
				self.trace[filename][frame] = np.array(self.trace[filename][frame])

		# Reject files without tracings 
		keep = [len(self.frames[f]) >= 2 for f in self.fnames]
		self.fnames = [f for (f, k) in zip(self.fnames, keep) if k]
		self.outcomes = [f for (f, k) in zip(self.outcomes, keep) if k]
		self.indexes = np.arange(np.shape(self.fnames)[0])

		self.indexes = np.arange(np.shape(self.fnames)[0])

	def __len__(self):
		# Denotes the number of batches per epoch
		return(int (np.floor(np.shape(self.fnames)[0])/self.batch_size))

	def __getitem__(self, idx):
		# Generate one batch of data and generate indexes of the batch
		indexes = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]
		X, ef, masks, ed_es_frames, edv, esv = self.__data_generation(indexes)
		X = np.expand_dims(X, 0)

		ed_es_frames = np.array(ed_es_frames, dtype =bool)

		# use packed tensor so that label contains the ef and the masks
		packed_output = PackedTensor(ef, masks, ed_es_frames, edv, esv)

		return X, packed_output
	
	def __data_generation(self, list_IDs_temp):
		# Retun the video (starting at the first annotated frame) and the mask of the first annotation 
		#X = np.empty((self.batch_size, self.max_length, 3, 128,128))
		X= []
		ejection = np.empty(self.batch_size)
		edv = np.empty(self.batch_size)
		esv = np.empty(self.batch_size)

		index = 0
		for i in list_IDs_temp:
			path = os.path.join(self.folder, "Videos", self.fnames[i])
			# Load video into np.array
			if not os.path.exists(path):
				print("File does not exist")

			vid_cap = cv2.VideoCapture(path)
			f = int(vid_cap.get(cv2.CAP_PROP_FRAME_COUNT))
			w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))
			h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

			v = np.zeros((f, w, h, 3), np.uint8)

			for count in range(f):
				success, frame = vid_cap.read()
				if not success:
					print("Failed to load frame #", count, ' of ', filename)
				frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
				v[count] = frame

			video = v.transpose((3,0,1,2))
			key = os.path.splitext(self.fnames[i])[0]

			video = video / 255.0
			video = np.moveaxis(video,0,1)

			frames = self.frames[self.fnames[i]]
			frames.sort()
			traces = self.trace[self.fnames[i]]
			first_frame = frames[0]

			nvideo = []

			# Start from frame ED -1 (if centering)
			# In some cases the test videos have fewer than max_len frames
			if (self.center):
				if  f - first_frame + 1 > self.max_length:
					nvideo.append(video[first_frame -1])
					nvideo.extend(video[first_frame:first_frame + self.max_length -1])
				else:
					nvideo.append(video[first_frame -1 ])
					nvideo.extend(video[first_frame:f])

					# zeros = np.zeros( (3, w, h))
					# for i in range(0, self.max_length - f + first_frame -1):
					# 	nvideo.append(zeros)

			# return all frames
			else:
				nvideo.append(video[0])
				nvideo.extend(video[1:f])


			#Load the mask for ES and ED
			if self.center:
				masks = np.empty((self.batch_size, np.shape(nvideo)[0], 128, 128, 1))
				ed_es_frames = np.zeros((self.batch_size, np.shape(nvideo)[0]))

				for f_no in frames:
					
					t = traces[f_no]
					x1, y1, x2, y2 = t[:, 0], t[:, 1], t[:, 2], t[:, 3]
					x = np.concatenate((x1[1:], np.flip(x2[1:])))
					y_ = np.concatenate((y1[1:], np.flip(y2[1:])))
					r, c = skimage.draw.polygon(np.rint(y_).astype(np.int), np.rint(x).astype(np.int), (w,h))
					mask = np.zeros((w,h), np.float32)
					mask[r, c] = 1
					mask = np.pad(mask, ((self.pad,self.pad),(self.pad,self.pad)), mode='constant', constant_values=0)
					mask = np.reshape(mask, (128,128, 1))

					if(f_no - first_frame < self.max_length):
						masks[index][f_no - first_frame] = mask
						ed_es_frames[index][f_no - first_frame] = 1.0
			else:
				masks = []
				ed_es_frames = []
				zeros = np.zeros((128, 128,1))

				for f_no in range(0, f):
					# if this frame has a trace
					if f_no in frames:
						t = traces[f_no]
						x1, y1, x2, y2 = t[:, 0], t[:, 1], t[:, 2], t[:, 3]
						x = np.concatenate((x1[1:], np.flip(x2[1:])))
						y_ = np.concatenate((y1[1:], np.flip(y2[1:])))
						r, c = skimage.draw.polygon(np.rint(y_).astype(np.int), np.rint(x).astype(np.int), (w,h))
						mask = np.zeros((w,h), np.float32)
						mask[r, c] = 1
						mask = np.pad(mask, ((self.pad,self.pad),(self.pad,self.pad)), mode='constant', constant_values=0)
						mask = np.reshape(mask, (128,128, 1))
						masks.append(mask)
						ed_es_frames.append(1.0)

						
					else:
						masks.append(zeros)
						ed_es_frames.append(0.0)




			# Padding 
			nvideo = np.pad(nvideo, ((0,0),(0,0),(self.pad,self.pad),(self.pad,self.pad)), mode='constant', constant_values=0)
			nvideo = np.swapaxes(nvideo, 1, 2)
			nvideo = np.swapaxes(nvideo, 2, 3)

			X = np.append(X, nvideo)
			X = X.reshape((-1, 128,128,3))

			
			ejection[index] = float(self.ejection[i]) / 100.0 #Divide by 10 to put in range 0-1
			edv[index] = float(self.edv[i])
			esv[index] = float(self.esv[i])
			index = index + 1

			#print(np.shape(self.edv))
			
			
		return tf.convert_to_tensor(X), tf.convert_to_tensor(ejection), tf.convert_to_tensor(masks), tf.convert_to_tensor(ed_es_frames), tf.convert_to_tensor(edv), tf.convert_to_tensor(esv)
				


